{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP2RlwQj/7MNX0S2PhkvpG+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zaheer-10/HuggingFace-Transformers_and_pipeline/blob/main/Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis Using Hugging face Transformers Pipeline"
      ],
      "metadata": {
        "id": "8V960ZEwLNRV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59Um2Z-h3nww"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xformers"
      ],
      "metadata": {
        "id": "3STD44I04ujt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline('sentiment-analysis')\n",
        "\n",
        "res = classifier(\"I love to travel\")\n",
        "\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32XbSU5k4AkN",
        "outputId": "7302dccb-cd15-461a-e5b2-3da4aa406272"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'POSITIVE', 'score': 0.9997954964637756}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\" , model = 'distilgpt2')\n",
        "\n",
        "res = generator('Today I will be learning about Hugging face and ',\n",
        "                max_length= 100,\n",
        "                num_return_sequences = 2)\n",
        "\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiXQ_8HE4n46",
        "outputId": "93978415-9584-4a03-d4b4-b311c4985cac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'generated_text': 'Today I will be learning about Hugging face and vernacular speech, and how to teach children how to understand the word and move on. And I will be sharing this book with you in the years to come.\\nToday, I hope, in this important chapter of this book, there are some other questions this students have answered before.\\nOn your part, I hope to explain in passing how I learned how to be funny, how to be funny, and how I taught that way to'}, {'generated_text': \"Today I will be learning about Hugging face and \\xa0 other styles, and I’ll be learning about it with the next update. In \\xa0 a few weeks, I will also be getting new tools for creating and maintaining \\xa0 style. I will also be using “I’ll be doing so” on\\xa0 the first \\xa0 update of my \\xa0 styles. \\xa0\\nSome of the new \\xa0 styles, including \\xa0 the\\xa0 'Saw�\"}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline('zero-shot-classification')\n",
        "\n",
        "res = classifier(\"I love to travel but \",\n",
        "                 candidate_labels = ['Tourism' , 'politics' , 'business'] ,)\n",
        "\n",
        "print(res)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZkxQYY46pQX",
        "outputId": "7b9a6431-baa0-44b3-9ef2-b8e420b8bd96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'sequence': 'I love to travel but ', 'labels': ['Tourism', 'business', 'politics'], 'scores': [0.8348780274391174, 0.0958399623632431, 0.06928205490112305]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This is how the pipeline works\n",
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer , AutoModelForSequenceClassification\n",
        "\n",
        "model_name = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "classifier = pipeline('sentiment-analysis' , model = model , tokenizer = tokenizer)\n",
        "\n",
        "res = classifier('The animal could not cross the road because it was tired')\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cFxvgwk8ZwA",
        "outputId": "db67f997-bf5e-4da8-8a32-f806c7048264"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'NEGATIVE', 'score': 0.9991163611412048}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's see more about tokenizer\n",
        "\n",
        "text = 'I am  going to achieve my Dream career beautifully soon  ASAP'\n",
        "output = tokenizer(text)\n",
        "print(output)\n",
        "print(\"\\n\")\n",
        "tokens = tokenizer.tokenize(text)\n",
        "print(tokens)\n",
        "print(\"\\n\")\n",
        "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(ids)\n",
        "print(\"\\n\")\n",
        "decode_strings =  tokenizer.decode(ids)\n",
        "print(decode_strings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjqpHS9D_i0t",
        "outputId": "a9b655ad-3752-4412-8c9b-e2c3486d8f95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [101, 1045, 2572, 2183, 2000, 6162, 2026, 3959, 2476, 17950, 2574, 17306, 2361, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "\n",
            "\n",
            "['i', 'am', 'going', 'to', 'achieve', 'my', 'dream', 'career', 'beautifully', 'soon', 'asa', '##p']\n",
            "\n",
            "\n",
            "[1045, 2572, 2183, 2000, 6162, 2026, 3959, 2476, 17950, 2574, 17306, 2361]\n",
            "\n",
            "\n",
            "i am going to achieve my dream career beautifully soon asap\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "encode_input = tokenizer(\"The tokenizer returns a dictionary with three important items:\")\n",
        "\n",
        "print(encode_input)\n",
        "\n",
        "tokenizer.decode(encode_input['input_ids'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "IYtpGFOhDoLp",
        "outputId": "fb2867c6-987b-4e1f-f684-c66a881dea1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [101, 1109, 22559, 17260, 5166, 170, 17085, 1114, 1210, 1696, 4454, 131, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[CLS] The tokenizer returns a dictionary with three important items : [SEP]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_sentences = [\n",
        "    \"But what about second breakfast?\",\n",
        "    \"Don't think he knows about second breakfast, Pip.\",\n",
        "    \"What about elevensies?\",\n",
        "]\n",
        "encoded_inputs = tokenizer(batch_sentences)\n",
        "print(encoded_inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2LfnNorEEO0",
        "outputId": "16ab07ac-36e1-455b-d192-13169d7aac8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [[101, 1252, 1184, 1164, 1248, 6462, 136, 102], [101, 1790, 112, 189, 1341, 1119, 3520, 1164, 1248, 6462, 117, 21902, 1643, 119, 102], [101, 1327, 1164, 5450, 23434, 136, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Set the padding parameter to True to pad the shorter sequences in the batch to match the longest sequence:**"
      ],
      "metadata": {
        "id": "AUBW8Y5WEOXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_sentences = [\n",
        "    \"But what about second breakfast?\",\n",
        "    \"Don't think he knows about second breakfast, Pip.\",\n",
        "    \"What about elevensies?\",\n",
        "]\n",
        "encoded_input = tokenizer(batch_sentences, padding=True)\n",
        "print(encoded_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FOj_XjyER9v",
        "outputId": "a4f68d30-268b-4963-ce04-9a7f67a37f91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [[101, 1252, 1184, 1164, 1248, 6462, 136, 102, 0, 0, 0, 0, 0, 0, 0], [101, 1790, 112, 189, 1341, 1119, 3520, 1164, 1248, 6462, 117, 21902, 1643, 119, 102], [101, 1327, 1164, 5450, 23434, 136, 102, 0, 0, 0, 0, 0, 0, 0, 0]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Set the truncation parameter to True to truncate a sequence to the maximum length accepted by the model:**"
      ],
      "metadata": {
        "id": "eOFJZX4VEcl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_sentences = [\n",
        "    \"But what about second breakfast?\",\n",
        "    \"Don't think he knows about second breakfast, Pip.\",\n",
        "    \"What about elevensies?\",\n",
        "]\n",
        "encoded_input = tokenizer(batch_sentences, padding=True, truncation=True)\n",
        "print(encoded_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTyOjvCIEe72",
        "outputId": "2a0c094a-4809-409d-8bf6-928fe22bcb89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [[101, 1252, 1184, 1164, 1248, 6462, 136, 102, 0, 0, 0, 0, 0, 0, 0], [101, 1790, 112, 189, 1341, 1119, 3520, 1164, 1248, 6462, 117, 21902, 1643, 119, 102], [101, 1327, 1164, 5450, 23434, 136, 102, 0, 0, 0, 0, 0, 0, 0, 0]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ">>> from transformers import AutoTokenizer, TFAutoModel\n",
        "\n",
        ">>> tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        ">>> model = TFAutoModel.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        ">>> inputs = tokenizer(\"Hello world!\", return_tensors=\"tf\")\n",
        ">>> outputs = model(**inputs)\n",
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUlCAXoNLqDc",
        "outputId": "c92b009f-3105-4183-cc63-16609feffc70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TFBaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=<tf.Tensor: shape=(1, 5, 768), dtype=float32, numpy=\n",
              "array([[[-0.14241204,  0.13353652, -0.12907045, ..., -0.35967988,\n",
              "         -0.05622251,  0.3605013 ],\n",
              "        [-0.35064834,  0.10419673,  0.6244456 , ..., -0.17610395,\n",
              "          0.48340222,  0.06443401],\n",
              "        [-0.24513134, -0.15731728,  0.6945201 , ..., -0.5654466 ,\n",
              "         -0.08940079, -0.18564393],\n",
              "        [-0.8247857 , -0.91192245, -0.6560709 , ...,  0.5074244 ,\n",
              "         -0.19388738, -0.1658766 ],\n",
              "        [ 0.8766518 ,  0.03524846, -0.12331428, ...,  0.27201617,\n",
              "         -0.6369    , -0.15850045]]], dtype=float32)>, pooler_output=<tf.Tensor: shape=(1, 768), dtype=float32, numpy=\n",
              "array([[-8.97564590e-01, -3.30401391e-01, -7.69419611e-01,\n",
              "         7.57992506e-01,  4.66781229e-01, -1.20347537e-01,\n",
              "         9.18352425e-01,  1.80867970e-01, -7.27160692e-01,\n",
              "        -9.99908864e-01, -4.47232902e-01,  8.91044021e-01,\n",
              "         9.66213226e-01,  5.49151361e-01,  9.43439186e-01,\n",
              "        -7.66053021e-01, -6.04690731e-01, -6.16537452e-01,\n",
              "         4.05723363e-01, -7.46444106e-01,  6.17388427e-01,\n",
              "         9.99742866e-01,  3.29905711e-02,  2.54143029e-01,\n",
              "         4.31060523e-01,  9.77317154e-01, -8.43280315e-01,\n",
              "         9.22973752e-01,  9.48708236e-01,  6.39942646e-01,\n",
              "        -7.36197114e-01,  9.09565687e-02, -9.76073086e-01,\n",
              "        -1.91145033e-01, -8.17169070e-01, -9.79070306e-01,\n",
              "         3.16353142e-01, -7.20125318e-01,  1.61237791e-01,\n",
              "         5.19983992e-02, -8.91015828e-01,  2.30017453e-01,\n",
              "         9.99674678e-01,  1.15036098e-02,  1.11757837e-01,\n",
              "        -3.55555475e-01, -9.99999702e-01,  2.84869522e-01,\n",
              "        -8.33390534e-01,  8.09872389e-01,  7.46638179e-01,\n",
              "         6.27617717e-01,  1.98473498e-01,  4.51853603e-01,\n",
              "         4.72418606e-01, -3.91685450e-03, -1.05704159e-01,\n",
              "         9.33397710e-02, -1.89059258e-01, -5.19457936e-01,\n",
              "        -5.78225374e-01,  2.80463815e-01, -8.22812676e-01,\n",
              "        -8.97642374e-01,  9.18903232e-01,  7.41173446e-01,\n",
              "        -5.99926189e-02, -3.16550344e-01,  2.82297865e-03,\n",
              "        -1.46523654e-01,  9.09528136e-01,  2.55872875e-01,\n",
              "         5.44930883e-02, -8.41865957e-01,  5.77714801e-01,\n",
              "         2.48039737e-01, -6.17320180e-01,  1.00000000e+00,\n",
              "        -6.48914039e-01, -9.54249978e-01,  5.54819882e-01,\n",
              "         6.88658953e-01,  5.57109833e-01, -3.34632337e-01,\n",
              "         4.79037374e-01, -1.00000000e+00,  3.41974854e-01,\n",
              "        -1.13320686e-01, -9.78181481e-01,  2.28874952e-01,\n",
              "         4.51608896e-01, -1.57196864e-01,  1.61954954e-01,\n",
              "         5.12396634e-01, -5.71384847e-01, -3.72961909e-01,\n",
              "        -2.85023034e-01, -8.02626491e-01, -2.19373509e-01,\n",
              "        -2.24057168e-01, -5.18688140e-03, -2.64172524e-01,\n",
              "        -2.28386372e-01, -3.74135345e-01,  2.69334078e-01,\n",
              "        -4.50770408e-01, -5.51734388e-01,  4.84298110e-01,\n",
              "         4.71780449e-02,  6.67271316e-01,  3.32011342e-01,\n",
              "        -2.94473320e-01,  5.06532192e-01, -9.49327350e-01,\n",
              "         6.18572414e-01, -2.45859310e-01, -9.75645840e-01,\n",
              "        -5.33957183e-01, -9.79240894e-01,  5.89340210e-01,\n",
              "        -2.34023511e-01, -2.75364578e-01,  9.46867704e-01,\n",
              "         1.52819991e-01,  3.02234918e-01,  1.11858658e-02,\n",
              "        -7.32344627e-01, -1.00000000e+00, -6.99510396e-01,\n",
              "        -5.05306423e-01, -2.75267661e-01, -2.06764027e-01,\n",
              "        -9.56074178e-01, -9.11091626e-01,  5.12320757e-01,\n",
              "         9.35193539e-01,  1.35466650e-01,  9.98773634e-01,\n",
              "        -2.06196189e-01,  9.22366023e-01, -4.91949469e-01,\n",
              "        -7.08136439e-01,  6.59905493e-01, -4.07024056e-01,\n",
              "         7.40803719e-01,  4.42370623e-01, -6.96969867e-01,\n",
              "         1.79585814e-01, -2.03109726e-01,  2.80313253e-01,\n",
              "        -6.50041759e-01, -2.20357761e-01, -6.89816236e-01,\n",
              "        -9.22664046e-01, -3.29418898e-01,  9.37541842e-01,\n",
              "        -4.76182312e-01, -8.93247008e-01, -1.47593275e-01,\n",
              "        -1.48917049e-01, -5.35202205e-01,  8.47376585e-01,\n",
              "         7.06553459e-01,  3.84884834e-01, -4.04296964e-01,\n",
              "         3.91954780e-01,  2.23511249e-01,  5.51958263e-01,\n",
              "        -8.11586380e-01, -1.88741669e-01,  3.36962491e-01,\n",
              "        -3.68828297e-01, -6.55798852e-01, -9.70580041e-01,\n",
              "        -3.47904772e-01,  4.86755043e-01,  9.84140038e-01,\n",
              "         7.16665983e-01,  2.30317369e-01,  7.05606818e-01,\n",
              "        -8.23272392e-02,  7.39097655e-01, -9.21616077e-01,\n",
              "         9.58931863e-01, -3.36378545e-01,  2.34012231e-01,\n",
              "         6.11096881e-02,  4.19188738e-01, -8.55757177e-01,\n",
              "         1.52758673e-01,  8.80898774e-01, -6.33111477e-01,\n",
              "        -8.37121725e-01,  6.51710331e-02, -4.30543333e-01,\n",
              "        -3.45569819e-01, -5.90762317e-01,  5.15028536e-01,\n",
              "        -2.62069017e-01, -2.46930659e-01,  6.13072664e-02,\n",
              "         8.76913607e-01,  9.87523437e-01,  8.02321136e-01,\n",
              "         1.47517502e-01,  6.88123882e-01, -8.93197060e-01,\n",
              "        -5.47031045e-01,  4.83560413e-02,  2.15404063e-01,\n",
              "         2.39044890e-01,  9.90135729e-01, -4.98798460e-01,\n",
              "        -1.37887463e-01, -9.22690868e-01, -9.77210641e-01,\n",
              "        -9.46874619e-02, -9.02986109e-01, -1.34679899e-01,\n",
              "        -7.00778008e-01,  5.16634881e-01,  2.44030818e-01,\n",
              "         6.12676919e-01,  3.61995280e-01, -9.92357075e-01,\n",
              "        -7.41320431e-01,  3.49220514e-01, -2.30571508e-01,\n",
              "         3.81906658e-01, -1.67798340e-01,  3.95564884e-02,\n",
              "         8.98091435e-01, -5.33498704e-01,  8.37219000e-01,\n",
              "         8.88394117e-01, -7.25139022e-01, -7.39647210e-01,\n",
              "         8.94066274e-01, -2.34078199e-01,  8.70295703e-01,\n",
              "        -5.63727260e-01,  9.74248230e-01,  8.47059965e-01,\n",
              "         8.32704782e-01, -8.96310151e-01, -5.62687039e-01,\n",
              "        -9.01591122e-01, -6.99725151e-01,  6.16894141e-02,\n",
              "         9.85588133e-02,  8.77489984e-01,  5.64036429e-01,\n",
              "         3.40487391e-01,  3.75821412e-01, -6.78335667e-01,\n",
              "         9.98272300e-01, -3.36016156e-02, -9.20015395e-01,\n",
              "         2.75712281e-01, -3.08645606e-01, -9.68957007e-01,\n",
              "         7.21657217e-01,  3.39533538e-01, -4.07353370e-03,\n",
              "        -4.14965332e-01, -6.46423638e-01, -9.27696824e-01,\n",
              "         9.31602240e-01,  6.09197244e-02,  9.90710258e-01,\n",
              "         4.61953543e-02, -9.39944088e-01, -6.68221533e-01,\n",
              "        -8.97852600e-01, -3.07158858e-01, -2.05004469e-01,\n",
              "        -3.87143672e-01, -8.12077001e-02, -9.45633173e-01,\n",
              "         4.34752107e-01,  4.15656030e-01,  4.91476774e-01,\n",
              "        -6.94451153e-01,  9.98299003e-01,  9.99998510e-01,\n",
              "         9.37474489e-01,  8.93659651e-01,  9.26512361e-01,\n",
              "        -9.97994661e-01, -2.93889463e-01,  9.99953151e-01,\n",
              "        -9.77303684e-01, -1.00000000e+00, -9.12337422e-01,\n",
              "        -6.95678055e-01,  3.72768253e-01, -1.00000000e+00,\n",
              "        -2.06093311e-01,  1.71245396e-01, -8.74477088e-01,\n",
              "         5.94124198e-01,  9.67195511e-01,  9.90949988e-01,\n",
              "        -1.00000000e+00,  6.59898877e-01,  9.26475048e-01,\n",
              "        -6.02012098e-01,  9.53468084e-01, -3.21775615e-01,\n",
              "         9.57936943e-01,  6.59320652e-01,  1.17684595e-01,\n",
              "        -2.45653644e-01,  3.24901581e-01, -8.82296026e-01,\n",
              "        -8.78554642e-01, -4.58936095e-01, -6.23061717e-01,\n",
              "         9.88815486e-01,  1.11267753e-01, -8.15041959e-01,\n",
              "        -8.97681415e-01, -2.56625414e-02, -2.00687036e-01,\n",
              "        -3.35758746e-01, -9.46153522e-01, -1.05966628e-01,\n",
              "         5.61967313e-01,  7.70343184e-01,  9.08752531e-02,\n",
              "         3.04404467e-01, -6.89377367e-01,  2.52428830e-01,\n",
              "        -1.70079738e-01,  3.36780965e-01,  6.26067400e-01,\n",
              "        -9.25410628e-01, -6.46682799e-01, -4.18122619e-01,\n",
              "        -1.57759815e-01, -5.80901802e-01, -9.35916662e-01,\n",
              "         9.50668037e-01, -4.77072924e-01,  7.97940373e-01,\n",
              "         1.00000000e+00,  1.28379405e-01, -8.67887616e-01,\n",
              "         6.24206662e-01,  2.04684839e-01,  4.34009405e-03,\n",
              "         1.00000000e+00,  7.73082733e-01, -9.59143877e-01,\n",
              "        -4.93826866e-01,  5.14473319e-01, -5.06434202e-01,\n",
              "        -4.60227758e-01,  9.96563613e-01, -2.78888136e-01,\n",
              "        -6.03740096e-01, -3.13786745e-01,  9.48697984e-01,\n",
              "        -9.75789309e-01,  9.82350051e-01, -8.92366171e-01,\n",
              "        -9.42378461e-01,  9.39814210e-01,  9.04973030e-01,\n",
              "        -6.83481514e-01, -4.29841608e-01,  1.24055654e-01,\n",
              "        -6.38801992e-01,  3.03335935e-01, -9.67494488e-01,\n",
              "         7.31080413e-01,  5.15031457e-01,  4.40690964e-02,\n",
              "         8.48785579e-01, -9.08549190e-01, -4.66380715e-01,\n",
              "         2.99094468e-01, -7.35680461e-01, -2.14306265e-01,\n",
              "         7.74391294e-01,  5.10140777e-01, -3.05487514e-01,\n",
              "         9.30424705e-02, -3.40411603e-01,  2.44321689e-01,\n",
              "        -9.63570774e-01,  3.49265963e-01,  1.00000000e+00,\n",
              "        -2.46827483e-01,  4.84178782e-01, -5.14740586e-01,\n",
              "         5.18160574e-02, -1.73877046e-01,  4.77605343e-01,\n",
              "         5.58684528e-01, -2.41631836e-01, -8.09159219e-01,\n",
              "         7.37226427e-01, -9.75238025e-01, -9.70198512e-01,\n",
              "         8.52612853e-01,  1.87272251e-01, -2.70896971e-01,\n",
              "         9.99977052e-01,  4.69832957e-01,  9.69785526e-02,\n",
              "         3.68514568e-01,  9.74144578e-01, -8.37745552e-04,\n",
              "         6.43763900e-01,  8.70528698e-01,  9.60590541e-01,\n",
              "        -1.87555566e-01,  5.19570887e-01,  8.73857737e-01,\n",
              "        -8.36678147e-01, -2.76626378e-01, -5.95594287e-01,\n",
              "        -1.23384856e-02, -8.85702252e-01,  8.24438632e-02,\n",
              "        -9.33756948e-01,  9.52006698e-01,  8.61297667e-01,\n",
              "         3.37199479e-01,  2.39666566e-01,  5.40952861e-01,\n",
              "         1.00000000e+00,  1.30893737e-01,  7.58658588e-01,\n",
              "        -6.53130651e-01,  9.13018227e-01, -9.98118579e-01,\n",
              "        -8.67905557e-01, -3.17519605e-01, -9.16056335e-03,\n",
              "        -7.32706547e-01, -3.13496292e-01,  2.65818089e-01,\n",
              "        -9.59440112e-01,  7.41255581e-01,  4.92145985e-01,\n",
              "        -9.93198037e-01, -9.86245096e-01, -2.14649081e-01,\n",
              "         9.04245317e-01, -4.90620770e-02, -9.37388718e-01,\n",
              "        -7.38776565e-01, -5.68684161e-01,  5.55928946e-01,\n",
              "        -2.03584552e-01, -9.34899211e-01, -1.90047726e-01,\n",
              "        -2.30249539e-01,  4.58989739e-01, -7.04432279e-02,\n",
              "         5.40629625e-01,  7.68463075e-01,  5.93926847e-01,\n",
              "        -1.95357770e-01, -1.44135907e-01, -2.65148636e-02,\n",
              "        -8.30495358e-01,  8.89956653e-01, -8.35597575e-01,\n",
              "        -8.25138092e-01, -1.76324025e-01,  1.00000000e+00,\n",
              "        -5.32089710e-01,  7.47466803e-01,  7.98797488e-01,\n",
              "         8.08148682e-01, -1.05707929e-01,  9.64869335e-02,\n",
              "         8.77530396e-01,  2.16734216e-01, -7.51002312e-01,\n",
              "        -8.12418163e-01, -9.01036084e-01, -3.28309387e-01,\n",
              "         6.36927426e-01,  8.23534094e-03,  5.53763151e-01,\n",
              "         7.12807536e-01,  6.49753392e-01,  1.44242764e-01,\n",
              "         3.02082896e-02, -1.53669938e-01,  9.99576211e-01,\n",
              "        -2.48226032e-01, -4.52666432e-02, -4.98612195e-01,\n",
              "         8.44527408e-03, -3.37643683e-01, -7.44545639e-01,\n",
              "         1.00000000e+00,  2.29091451e-01,  3.03998709e-01,\n",
              "        -9.82245743e-01, -7.75807500e-01, -9.38251197e-01,\n",
              "         9.99992311e-01,  8.04934800e-01, -6.94606543e-01,\n",
              "         6.75831735e-01,  7.15597212e-01, -7.59554952e-02,\n",
              "         8.82801712e-01, -8.87961984e-02, -3.67759526e-01,\n",
              "         3.03575635e-01,  9.05779377e-02,  9.35697794e-01,\n",
              "        -5.47134399e-01, -9.40639913e-01, -5.18537700e-01,\n",
              "         3.64066809e-01, -9.45865035e-01,  9.98844206e-01,\n",
              "        -4.66337830e-01, -2.20361724e-01, -4.29094434e-01,\n",
              "         1.98117137e-01,  8.02957833e-01, -1.12372518e-01,\n",
              "        -9.75931287e-01,  3.25433468e-03,  2.23870203e-01,\n",
              "         9.44066167e-01,  2.31521845e-01, -5.37412167e-01,\n",
              "        -9.01524842e-01,  7.29721606e-01,  6.46784663e-01,\n",
              "        -8.52613091e-01, -9.22795951e-01,  9.42166626e-01,\n",
              "        -9.85776246e-01,  6.67548239e-01,  1.00000000e+00,\n",
              "         3.42246950e-01, -1.67607903e-01,  7.70930648e-02,\n",
              "        -3.98363799e-01,  2.26251587e-01, -2.20408708e-01,\n",
              "         7.36118972e-01, -9.27429736e-01, -3.64905775e-01,\n",
              "        -1.75400525e-01,  2.94677585e-01, -1.13031209e-01,\n",
              "         2.64014661e-01,  6.92004144e-01,  1.54299885e-01,\n",
              "        -4.00825262e-01, -5.26402593e-01,  2.40871832e-02,\n",
              "         4.39488083e-01,  8.60768616e-01, -2.68656701e-01,\n",
              "        -1.03878617e-01,  7.55877420e-03, -1.22412130e-01,\n",
              "        -9.13759530e-01, -2.13477552e-01, -2.96733677e-01,\n",
              "        -9.99884129e-01,  6.94553256e-01, -1.00000000e+00,\n",
              "         2.83679515e-01,  8.67338106e-02, -1.22202791e-01,\n",
              "         7.92056382e-01,  1.54896146e-02,  4.93106961e-01,\n",
              "        -7.31052220e-01, -8.14439893e-01,  5.08271933e-01,\n",
              "         7.23584771e-01, -2.93487012e-01, -5.17903268e-01,\n",
              "        -6.97735131e-01,  2.46367216e-01, -1.55264623e-02,\n",
              "         2.13391244e-01, -5.18059075e-01,  7.81371474e-01,\n",
              "        -1.73006251e-01,  1.00000000e+00,  1.95270032e-01,\n",
              "        -7.54101992e-01, -9.82624769e-01,  1.54157266e-01,\n",
              "        -2.14571670e-01,  9.99999642e-01, -9.32848334e-01,\n",
              "        -9.15725529e-01,  2.94295371e-01, -6.96171999e-01,\n",
              "        -8.32604766e-01,  2.68195182e-01, -3.46822962e-02,\n",
              "        -7.88624585e-01, -8.58201265e-01,  9.51014280e-01,\n",
              "         9.46895182e-01, -5.51998675e-01,  4.58794147e-01,\n",
              "        -3.44412625e-01, -5.60574949e-01, -4.51467671e-02,\n",
              "         7.02480733e-01,  9.71325576e-01,  2.62537539e-01,\n",
              "         8.91367435e-01,  4.23019230e-01, -7.37066939e-02,\n",
              "         9.49699879e-01,  1.64449975e-01,  6.13815188e-01,\n",
              "         1.02700651e-01,  1.00000000e+00,  2.79830992e-01,\n",
              "        -8.86763573e-01,  1.44037589e-01, -9.72443700e-01,\n",
              "        -1.68641254e-01, -9.52210188e-01,  2.62314171e-01,\n",
              "         2.79974073e-01,  8.93156528e-01, -2.33830988e-01,\n",
              "         9.42953110e-01, -5.38330674e-01,  4.35934663e-02,\n",
              "        -7.92427003e-01, -3.19328070e-01,  3.56163383e-01,\n",
              "        -9.02702391e-01, -9.72061276e-01, -9.73007143e-01,\n",
              "         6.84351146e-01, -4.21057791e-01,  4.47234251e-02,\n",
              "         1.24398418e-01,  7.17439922e-03,  3.59158039e-01,\n",
              "         4.43928510e-01, -1.00000000e+00,  9.29621518e-01,\n",
              "         3.85572642e-01,  8.54920089e-01,  9.29922104e-01,\n",
              "         7.06250370e-01,  4.83698934e-01,  2.32697666e-01,\n",
              "        -9.75407898e-01, -9.82179463e-01, -3.29320371e-01,\n",
              "        -2.11626038e-01,  7.50838041e-01,  6.32021904e-01,\n",
              "         8.88561249e-01,  4.32511955e-01, -5.04042566e-01,\n",
              "        -6.70288727e-02, -2.95051932e-01, -3.28066438e-01,\n",
              "        -9.85684216e-01,  4.34464902e-01, -5.86578965e-01,\n",
              "        -9.77243185e-01,  9.36505735e-01, -1.37082368e-01,\n",
              "        -1.36651605e-01, -9.29036587e-02, -6.66351080e-01,\n",
              "         9.72776532e-01,  7.07072258e-01,  4.32035208e-01,\n",
              "         8.79153684e-02,  4.72166657e-01,  8.39901507e-01,\n",
              "         9.49930966e-01,  9.72189605e-01, -6.72018886e-01,\n",
              "         8.32794607e-01, -5.41667581e-01,  4.11254734e-01,\n",
              "         3.47185522e-01, -9.07910585e-01,  9.18324441e-02,\n",
              "         2.05055401e-01, -2.86097497e-01,  1.53520092e-01,\n",
              "        -1.13035478e-01, -9.83952224e-01,  1.86310023e-01,\n",
              "        -2.08633810e-01,  6.11660302e-01, -2.93818265e-01,\n",
              "         5.85788712e-02, -3.70756775e-01, -3.74017134e-02,\n",
              "        -6.26589715e-01, -7.59351671e-01,  5.65075696e-01,\n",
              "         5.02579153e-01,  8.77030849e-01,  8.07350636e-01,\n",
              "        -6.90272152e-02, -6.45564139e-01, -2.23078936e-01,\n",
              "        -7.02029645e-01, -8.92385244e-01,  9.44534838e-01,\n",
              "        -2.74519064e-02, -3.41300935e-01,  5.09773552e-01,\n",
              "        -1.50048614e-01,  5.01545429e-01,  9.24913585e-02,\n",
              "        -3.13713819e-01, -3.98607284e-01, -6.51972473e-01,\n",
              "         8.36093009e-01,  4.20149490e-02, -5.35046637e-01,\n",
              "        -7.03999639e-01,  5.67307353e-01,  3.10901254e-01,\n",
              "         9.99739945e-01, -6.71309352e-01, -8.31159949e-01,\n",
              "        -1.65926099e-01, -3.91968995e-01,  2.81660765e-01,\n",
              "        -4.29599792e-01, -1.00000000e+00,  3.98460895e-01,\n",
              "        -3.72099310e-01,  6.32362902e-01, -6.84133708e-01,\n",
              "         4.88270581e-01, -7.24337757e-01, -9.82196987e-01,\n",
              "        -1.62524998e-01,  4.21673581e-02,  6.86585009e-01,\n",
              "        -4.70854849e-01, -7.61908948e-01,  4.80941892e-01,\n",
              "        -1.66886047e-01,  9.53173578e-01,  8.15535367e-01,\n",
              "        -3.68654639e-01,  1.13016188e-01,  6.03762686e-01,\n",
              "        -6.55948639e-01, -6.19980335e-01,  9.09516692e-01]], dtype=float32)>, past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    }
  ]
}